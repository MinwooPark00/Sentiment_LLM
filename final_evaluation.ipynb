{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60654034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ [SETUP] Hugging Face cache directory set to: /output/huggingface_cache\n",
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "‚úÖ [CHECKPOINT] Imports successful\n",
      "CUDA available: True\n",
      "Using device: cuda\n",
      "- Device: NVIDIA GeForce RTX 3090\n",
      "‚úÖ [CHECKPOINT] Seed set\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# Project: Adapting from Sentence-level to Document-level Sentiment Analysis\n",
    "# Phase 4: Final Evaluation and Inference Demonstration\n",
    "# =================================================================\n",
    "\n",
    "# Import libraries\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# =================================================================\n",
    "# ENVIRONMENT SETUP\n",
    "# =================================================================\n",
    "\n",
    "# Set Hugging Face cache directory to a larger, persistent volume\n",
    "cache_dir = \"/output/huggingface_cache\"\n",
    "os.environ['HF_HOME'] = cache_dir\n",
    "os.environ['HF_DATASETS_CACHE'] = os.path.join(cache_dir, \"datasets\")\n",
    "os.environ['TRANSFORMERS_CACHE'] = os.path.join(cache_dir, \"models\")\n",
    "\n",
    "# Prevent tokenizer parallelism issues\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Ensure the cache directory exists\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "print(f\"‚úÖ [SETUP] Hugging Face cache directory set to: {cache_dir}\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "try:\n",
    "    from unsloth import FastLanguageModel\n",
    "    from peft import PeftModel\n",
    "    from datasets import load_dataset\n",
    "    from transformers import AutoTokenizer\n",
    "    print(\"‚úÖ [CHECKPOINT] Imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå ImportError: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- Basic Setup ---\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"- Device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n",
    "print(\"‚úÖ [CHECKPOINT] Seed set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42fed8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Student Model: unsloth/Llama-3.2-1B-unsloth-bnb-4bit with adapter from ./train_outputs/sst2_finetune/final_adapter\n",
      "==((====))==  Unsloth 2025.6.2: Fast Llama patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 1. Max memory: 23.684 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "‚úÖ [CHECKPOINT] Student model and adapter loaded successfully.\n",
      "Loading best instruction from ./optimization_results/best_result.json\n",
      "‚úÖ [CHECKPOINT] Best instruction loaded successfully.\n",
      "    - Best Iteration: 4\n",
      "    - Best Accuracy: 80.60%\n",
      "    - Best Instruction: \"Classify the overall sentiment of the following movie review as either \"Positive\" or \"Negative\". To make this classification, consider the entire text, not just a single sentence. If the review expresses a general attitude that is overwhelmingly positive (e.g., praising the movie, enjoying the experience), output \"Positive\". If the review expresses a general attitude that is overwhelmingly negative (e.g., criticizing the movie, disliking the experience), output \"Negative\". When dealing with mixed reviews that mention both positive and negative aspects, look for the overall tone of the review. If the review's overall tone is more positive than negative, output \"Positive\". If the review's overall tone is more negative than positive, output \"Negative\". If the review is neutral, meaning it doesn't express a clear positive or negative attitude, output \"Neutral\".\"\n",
      "Loading IMDb test dataset...\n",
      "‚úÖ [CHECKPOINT] IMDb dataset loaded with 25000 examples.\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# LOAD MODELS, DATA, AND BEST INSTRUCTION\n",
    "# =================================================================\n",
    "\n",
    "# --- Configuration ---\n",
    "STUDENT_MODEL_NAME = \"unsloth/Llama-3.2-1B-unsloth-bnb-4bit\"\n",
    "ADAPTER_PATH = \"./train_outputs/sst2_finetune/final_adapter\" \n",
    "BEST_RESULT_PATH = \"./optimization_results/best_result.json\"\n",
    "OUTPUT_DIR = \"./optimization_results\"\n",
    "STUDENT_MAX_SEQ_LENGTH = 8192\n",
    "\n",
    "# --- Load Student Model (Fine-tuned on SST2) ---\n",
    "print(f\"Loading Student Model: {STUDENT_MODEL_NAME} with adapter from {ADAPTER_PATH}\")\n",
    "try:\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=STUDENT_MODEL_NAME,\n",
    "        max_seq_length=STUDENT_MAX_SEQ_LENGTH,\n",
    "        load_in_4bit=True,\n",
    "    )\n",
    "    model.load_adapter(ADAPTER_PATH)\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    print(\"‚úÖ [CHECKPOINT] Student model and adapter loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load student model: {e}\")\n",
    "    raise\n",
    "    \n",
    "# --- Load Best Instruction ---\n",
    "print(f\"Loading best instruction from {BEST_RESULT_PATH}\")\n",
    "try:\n",
    "    with open(BEST_RESULT_PATH, 'r') as f:\n",
    "        best_result_data = json.load(f)\n",
    "    best_instruction = best_result_data[\"best_instruction\"]\n",
    "    print(\"‚úÖ [CHECKPOINT] Best instruction loaded successfully.\")\n",
    "    print(f\"    - Best Iteration: {best_result_data['best_iteration']}\")\n",
    "    print(f\"    - Best Accuracy: {best_result_data['best_accuracy']}\")\n",
    "    print(f\"    - Best Instruction: \\\"{best_instruction}\\\"\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load best instruction file: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- Load IMDb Dataset ---\n",
    "print(\"Loading IMDb test dataset...\")\n",
    "try:\n",
    "    imdb_dataset = load_dataset(\"imdb\", split=\"test\")\n",
    "    print(f\"‚úÖ [CHECKPOINT] IMDb dataset loaded with {len(imdb_dataset)} examples.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load IMDb dataset: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae12901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Full Evaluation with 'Initial' Instruction ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (Initial): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25000/25000 [41:18<00:00, 10.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- INITIAL PERFORMANCE METRICS ---\n",
      "Instruction Used: \"Classify the sentiment of the following movie review as either \"Positive\" or \"Negative\".\"\n",
      "Total Samples Evaluated: 25000\n",
      "Correct Predictions: 14933\n",
      "Final Accuracy: 59.73%\n",
      "----------------------------------------\n",
      "\n",
      "--- Starting Full Evaluation with 'Best Optimized' Instruction ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (Best Optimized): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25000/25000 [31:08<00:00, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BEST OPTIMIZED PERFORMANCE METRICS ---\n",
      "Instruction Used: \"Classify the overall sentiment of the following movie review as either \"Positive\" or \"Negative\". To make this classification, consider the entire text, not just a single sentence. If the review expresses a general attitude that is overwhelmingly positive (e.g., praising the movie, enjoying the experience), output \"Positive\". If the review expresses a general attitude that is overwhelmingly negative (e.g., criticizing the movie, disliking the experience), output \"Negative\". When dealing with mixed reviews that mention both positive and negative aspects, look for the overall tone of the review. If the review's overall tone is more positive than negative, output \"Positive\". If the review's overall tone is more negative than positive, output \"Negative\". If the review is neutral, meaning it doesn't express a clear positive or negative attitude, output \"Neutral\".\"\n",
      "Total Samples Evaluated: 25000\n",
      "Correct Predictions: 19911\n",
      "Final Accuracy: 79.64%\n",
      "-----------------------------------------------\n",
      "\n",
      "=================================\n",
      "=== FINAL PERFORMANCE SUMMARY ===\n",
      "=================================\n",
      "Initial Baseline Accuracy: 59.73%\n",
      "Optimized Best Accuracy:   79.64%\n",
      "---------------------------------\n",
      "Total Improvement:         +19.91%p\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# EVALUATION LOGIC\n",
    "# =================================================================\n",
    "\n",
    "label_map = {0: \"Negative\", 1: \"Positive\"}\n",
    "BASE_PROMPT_TEMPLATE = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{review}\n",
    "\n",
    "### Response:\n",
    "{response}\"\"\"\n",
    "\n",
    "def run_full_evaluation(instruction_text, dataset_name):\n",
    "    \"\"\"Runs evaluation on the full dataset with a given instruction.\"\"\"\n",
    "    print(f\"\\n--- Starting Full Evaluation with '{dataset_name}' Instruction ---\")\n",
    "    \n",
    "    prompt_template = BASE_PROMPT_TEMPLATE.format(\n",
    "        instruction=instruction_text,\n",
    "        review=\"{review}\",\n",
    "        response=\"{response}\"\n",
    "    )\n",
    "\n",
    "    correct_predictions = 0\n",
    "    num_samples = len(imdb_dataset)\n",
    "\n",
    "    for i in tqdm(range(num_samples), desc=f\"Evaluating ({dataset_name})\"):\n",
    "        sample = imdb_dataset[i]\n",
    "        text = sample[\"text\"]\n",
    "        true_label_str = label_map.get(sample[\"label\"])\n",
    "        \n",
    "        prompt = prompt_template.format(review=text, response=\"\")\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=STUDENT_MAX_SEQ_LENGTH).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=5, pad_token_id=tokenizer.eos_token_id)\n",
    "        \n",
    "        prediction_text = tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True).strip()\n",
    "        predicted_label = \"Positive\" if \"Positive\" in prediction_text else \"Negative\" if \"Negative\" in prediction_text else \"Unknown\"\n",
    "        \n",
    "        if predicted_label == true_label_str:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    final_accuracy = (correct_predictions / num_samples) * 100\n",
    "    \n",
    "    print(f\"\\n--- {dataset_name.upper()} PERFORMANCE METRICS ---\")\n",
    "    print(f\"Instruction Used: \\\"{instruction_text}\\\"\")\n",
    "    print(f\"Total Samples Evaluated: {num_samples}\")\n",
    "    print(f\"Correct Predictions: {correct_predictions}\")\n",
    "    print(f\"Final Accuracy: {final_accuracy:.2f}%\")\n",
    "    print(\"---------------------------------\" + \"-\"*len(dataset_name))\n",
    "    return final_accuracy\n",
    "\n",
    "# Run evaluation for the initial instruction\n",
    "initial_instruction = 'Classify the sentiment of the following movie review as either \"Positive\" or \"Negative\".'\n",
    "initial_accuracy = run_full_evaluation(initial_instruction, \"Initial\")\n",
    "\n",
    "# Run evaluation for the best instruction found\n",
    "best_accuracy = run_full_evaluation(best_instruction, \"Best Optimized\")\n",
    "\n",
    "# --- Final Comparison ---\n",
    "print(\"\\n=================================\")\n",
    "print(\"=== FINAL PERFORMANCE SUMMARY ===\")\n",
    "print(\"=================================\")\n",
    "print(f\"Initial Baseline Accuracy: {initial_accuracy:.2f}%\")\n",
    "print(f\"Optimized Best Accuracy:   {best_accuracy:.2f}%\")\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Total Improvement:         {best_accuracy - initial_accuracy:+.2f}%p\")\n",
    "print(\"=================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
